{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk import punkt\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "from math import log, sqrt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "%matplotlib inline\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "stop = set(stopwords.words('english'))\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from tqdm import tqdm\n",
    "pd.options.display.max_columns = 999\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from textblob import Word\n",
    "from textblob import TextBlob\n",
    "from textblob import TextBlob\n",
    "from wordcloud import WordCloud\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "morestops = ['light', 'main', 'appetizer', 'city', 'left', 'felt', 'pot', 'chinese', 'hot', 'name', 'sure', 'walked',\n",
    "            'sit', 'door', 'yelp', 'group', 'options', 'portions', 'find', 'absolutely', 'neighborhood','ice',\n",
    "            'desserts', 'enjoyed', 'courses', 'busy', 'large', 'friday', '4', 'able', 'packed', 'reservations',\n",
    "            'saturday', 'reservation', 'full', 'average', 'feel', 'looking', 'gave', 'brought', 'must', 'york',\n",
    "            'michelin', 'not', 'can', 'tell', 'home', 'awesome', 'different', 'bbq', 'lot', 'size', 'amount', 'plate',\n",
    "            'long', 'theres', 'open', 'line', 'big', 'crowded', 'seated', 'lovely', 'cozy', 'waiting', 'sat', 'seats',\n",
    "            'inside', 'cool', 'wall', 'walk', 'front', 'free', 'old', 'sometimes', 'usually', 'yes', 'theyre', 'youll',\n",
    "            'often', 'isnt', 'things', 'gem', 'bill', 'cash', 'bland', 'room', 'end', 'view', 'evening','waited', \n",
    "            '20', '5', 'friendly', 'loud', 'fun', 'mexican', 'coming', 'enjoy', 'greek', 'outdoor', 'warm', 'not',\n",
    "            'can', 'oh', 'wrong', 'na', 'street', 'cocktail', 'beers', 'glass', 'brooklyn', 'manhattan', 'may', 'bottle',\n",
    "            'started', 'tender', 'slow', 'sauce', 'sweet', 'seating', 'lunch', 'menu', 'stars', 'quality', 'nothing', \n",
    "            'worth', 'reservation', 'recommend', 'spot', 'happy', 'everything', 'cooked', 'bread', 'outside', 'tables', \n",
    "            'location', 'mac', 'course', 'made', 'never', 'another', 'know', 'take', 'korean', 'french', 'italian', \n",
    "            'sauce', 'area', 'even', 'said', 'took', 'people', 'could', 'wait', 'first', 'always', 'go', 'love', 'new', 'im', \n",
    "            'come', 'favorite', 'times', 'excellent', 'night','hour', 'pretty', 'bit', 'small', 'little', \n",
    "            'though', 'much', 'think', 'better', 'quite', 'spicy','side', 'time', 'definitely', 'would', 'delicious', \n",
    "            'dont', 'dish', 'ordered', 'table', 'place', 'nice', 'bar', 'also', 'came', 'great', 'good', 'amazing', \n",
    "            'restaurant', 'really', 'well', 'bad', 'minutes', 'nice', 'back', 'best', 'ive', 'like','dont','get', 'us', \n",
    "            'came', 'order','minutes','one', 'asked', 'got', 'didnt', 'perfectly', 'meal', 'dishes', 'cream', 'want',\n",
    "            'make', 'youre', 'eat', 'way', 'thats', 'say', 'need', 'see', 'something', 'dinner', 'every', 'highly', \n",
    "            'wonderful', 'nyc', 'perfect', 'told', 'drinks', 'wanted', 'went', 'wasnt', 'taste', 'overall', '2', '3', \n",
    "            'around', 'japanese', 'flavor', 'rib', 'can', 'not', 'oh', 'lol', 'point', 'wife', 'brooklyn',' vietnamese', \n",
    "            'bite', 'n', 'enough', 'although', 'expect', 'per', 'person', 'tender', 'flavorful', 'green', 'tasted',\n",
    "            'texture', 'give', 'going', 'still', 'ever', 'reviews', 'review', 'cant', 'many', 'restaurants', 'wine',\n",
    "            'dining', 'top', 'beautiful', 'special', 'tasting', 'birthday', 'incredible', 'fried', 'sunday', 'water', \n",
    "            'friend', 'drink', 'friends', 'super', 'music', 'cocktails', 'vibe', 'space', 'coffee', 'medium', 'meat',\n",
    "            'rare', 'grill', 'cut', 'bone', 'roasted', 'fresh', 'brunch', 'breakfast', 'dessert', 'toast', 'two', 'dessert',\n",
    "            'seafood', 'perfectly', 'meal', 'dishes', 'cream', 'want', 'make', 'youre', 'eat', 'way', 'thats', 'say', 'need', \n",
    "            'see', 'something', 'dinner', 'every', 'highly', 'wonderful', 'nyc', 'perfect', 'told', 'drinks', 'wanted', \n",
    "            'went', 'wasnt', 'taste', 'overall', '2', '3', 'around', 'japanese', 'flavor', 'rib', 'can', 'not', 'oh', 'lol',\n",
    "            'point', 'wife', 'brooklyn', 'vietnamese', 'bite', 'n', 'enough', 'although', 'expect', 'per', 'person', 'tender',\n",
    "            'flavorful', 'green', 'tasted', 'texture', 'tea', 'thai', 'ask', 'arrived', 'party', 'cake', 'date', 'selection',\n",
    "            'cute', 'try', 'bowl', 'probably', 'high', 'however', 'id', 'decent', 'maybe', 'places', 'village', 'east', 'tapas', \n",
    "            'west', 'sangria', 'de', 'margaritas', 'dan', 'visit', 'last', 'family', 'years', 'everyone', 'thank', 'hearing',\n",
    "            'tons','rave','finally','decided','actually','second','puts','bring','youd','impress','list', 'personally', \n",
    "            'neighborhood', 'loved', 'fantastic', 'absolutely', 'grilled', 'tasty', 'crispy', 'portion', 'served', 'day', \n",
    "            'right', 'party', 'next', 'since', 'away', 'arrived', 'ok', 'however', 'maybe', 'tip', 'star', 'okay', 'short', \n",
    "            'flavors', 'vegan', 'la', 'unique', 'ingredients', 'interesting', 'cuisine', 'time', 'definitely', 'would', \n",
    "            'delicious', 'dont', 'dish', 'ordered', 'table', 'place', 'nice', 'bar', 'also', 'came', 'great', 'good', \n",
    "            'amazing', 'restaurant', 'really', 'well', 'bad', 'minutes', 'nice', 'back', 'best', 'ive', 'like','dont',\n",
    "            'get', 'us', 'came', 'order','minutes','one', 'asked', 'got', 'didnt','thing', 'might', 'makes', 'eating', \n",
    "            'real', 'let', 'tried', 'far', 'reasonable', 'husband', 'truly', 'pm', 'am', 'else', 'seemed', 'someone', \n",
    "            'good', 'like', 'really', 'place', 'would', 'pretty', 'bit', 'much', 'better', 'great', 'amazing', 'place', \n",
    "            'delicous', 'back', 'good', 'definitely', 'best', 'love', 'recommend', 'good', 'great', 'place', 'nice', \n",
    "            'really', 'bar', 'back', 'definitely', 'came', 'pretty', 'dish', 'ordered', 'dessert', 'happy', 'hour', \n",
    "            'drinks', 'beer', 'bar', 'new', 'always', 'one', 'go', 'location', 'get', 'place', 'york', 'us', 'time',\n",
    "            'table', 'one', 'order', 'get', 'came', 'would', 'back', 'even', 'course', 'wine', 'dining', 'meal', 'course',\n",
    "            'dishes', 'impeccable', 'juicy', 'later', 'margarita', 'fine', 'hard', 'less', 'especially', 'items', 'given',\n",
    "            'vietnamese', 'late', 'not', 'can', 'here', 'there', 'yummy', 'can', 'din', 'seat', 'look', 'crowd', 'work', \n",
    "            'amaze', 'pay', 'seem', 'share', 'start']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = ['thing', 'might', 'makes', 'eating', 'real', 'let', 'tried', 'far', 'reasonable', 'husband', 'truly',\n",
    "        'pm', 'am', 'else', 'seemed', 'someone', 'good', 'like', 'really', 'place', 'would', 'pretty', 'bit', 'much',\n",
    "        'better', 'great', 'amazing', 'place', 'delicous', 'back', 'good', 'definitely', 'best', 'love', 'recommend',\n",
    "        'good', 'great', 'place', 'nice', 'really', 'bar', 'back', 'definitely', 'came', 'pretty', 'dish', 'ordered',\n",
    "        'dessert', 'happy', 'hour', 'drinks', 'beer', 'bar', 'new', 'always', 'one', 'go', 'location', 'get', 'place',\n",
    "        'york', 'us', 'time', 'table', 'one', 'order', 'get', 'came', 'would', 'back', 'even', 'course', 'waaaine',\n",
    "        'dining', 'meal', 'course', 'dishes', 'impeccable', 'juicy', 'later', 'margarita', 'fine', 'hard', 'less',\n",
    "        'especially', 'items', 'given', 'vietnamese', 'late', 'not', 'can', 'astoria', 'steakhouse', 'terrible', 'empty',\n",
    "        'like', 'boat', 'leave', 'call', 'offer', 'consider', 'disappoint', 'without', 'stop', 'delivery', 'patio', 'smoke',\n",
    "        'dress', 'keep', 'market', 'park', 'floor', 'hotel', 'th', 'upstairs', 'locate', 'near', 'pair', 'piece', 'solid', \n",
    "        'set', 'fill', 'interior', 'put', 'chinatown', 'piece', 'shop', 'solid', 'season', 'boy', 'welcome', 'return',\n",
    "        'price', 'expensive', 'chea', 'overprice', 'cost', 'money', 'spend', 'receive', 'include', 'quick', 'fast', 'black',\n",
    "        'salt', 'add', 'charge', 'sum', 'bottomless', 'poach', 'kitchen', 'plat', 'mean', 'anything', 'three', 'tiny', 'level',\n",
    "        'dry', 'half', 'use', 'anything', 'mean', 'honestly', 'almost', 'summer', 'close', 'rich', 'salty', 'red', 'couple', \n",
    "        'plat', 'show', 'occasion', 'least', 'lack', 'reason', 'either', 'miss', 'hours', 'rat', 'guess', 'instead',\n",
    "        'understand', 'mind', 'outstanding', 'platter', 'rude', 'greet', 'guy', 'girl', 'woman', 'man', 'cold',\n",
    "        'soft', 'white', 'fixe', 'pre', 'prix', 'refresh', 'le', 'range', 'terrific', 'craft', 'hill', 'non', 'pot',\n",
    "        'win', 'live', 'weekend', 'surprise', 'shack', 'po', 'raw', 'dozen']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop.update(morestops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop.update(stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "699"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string \n",
    "def remove_punctuations(text):\n",
    "    for punctuation in string.punctuation:\n",
    "        text = text.replace(punctuation, ' ')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursive_len(item):\n",
    "    if type(item) == list:\n",
    "        return sum(recursive_len(subitem) for subitem in item)\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Sample Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sample = df.iloc[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sampledrop = ['review_'+str(x) for x in range(125,140)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sampledrop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sample.drop(columns=sampledrop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sample.drop(columns=['Unnamed: 0', 'price', 'rating', 'restaurant_id', 'review_count'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rva = ['review_'+ str(x+1) for x in range(124)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = df.fillna(value=str('none'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.drop(columns=rva, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sample.drop(columns=rva, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sample.drop(columns=['restaurant_name'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for y in rva:\n",
    "    sample[y] = sample[y].apply(remove_punctuations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for y in rva:\n",
    "    sample[y] = sample[y].apply(lambda x: ' '.join([word.lower() for word in x.split() if word not in (stop)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for y in rva:\n",
    "    sample[y] = sample[y].apply(lambda x: ' '.join([lemmatizer.lemmatize(word, pos = 'r') for word in x.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for y in tqdm(rva):\n",
    "    sample['token_'+y]= sample[y].apply(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sample.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "tokenslist = sample.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(len(tokenslist[0][10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tokenslist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#FUNCTION TO FLATTEN TOKEN LIST\n",
    "\n",
    "def flatten( alist ):\n",
    "     newlist = []\n",
    "     for item in alist:\n",
    "         if isinstance(item, list):\n",
    "             newlist = newlist + flatten(item)\n",
    "         else:\n",
    "             newlist.append(item)\n",
    "     return newlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "flattoken = flatten(tokenslist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(len(flattoken))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "flattoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import corpora\n",
    "dictionary = corpora.Dictionary(sample.values[0])\n",
    "\n",
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in sample.values[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Creating the object for LDA model using gensim library\n",
    "Lda = gensim.models.ldamodel.LdaModel\n",
    "\n",
    "# Running and Trainign LDA model on the document term matrix.\n",
    "ldamodel = Lda(doc_term_matrix, num_topics=10, id2word = dictionary, passes=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(ldamodel.print_topics(num_topics=10, num_words=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cleanedManhattanfull.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rva = ['review_'+ str(x+1) for x in range(139)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rem = ['review_'+ str(x+1) for x in range(124, 139)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(value=str('none'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Unnamed: 0', 'price', 'rating', 'restaurant_id', 'review_count'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for y in rva:\n",
    "    df[y] = df[y].apply(remove_punctuations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for y in rva:\n",
    "    df[y] = df[y].apply(lambda x: ' '.join([word.lower() for word in x.split() if word.lower() not in stop]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for y in tqdm(rva):\n",
    "    df[y] = df[y].apply(lambda x: ' '.join([lemmatizer.lemmatize(word, pos = 'r') for word in x.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for y in tqdm(rva):\n",
    "    df['token_'+y]= df[y].apply(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=rva, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['restaurant_name'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenslist = df.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tokenslist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(tokenslist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['token_review_129'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "for row in tokenslist:\n",
    "    if len(row) > 1:\n",
    "        temp.extend(row)\n",
    "#remove below line for full run        \n",
    "# temp = temp[0:50] + temp[1000:1100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def deleting(list_1,del_name):\n",
    "    for sub_list in tqdm(list_1):\n",
    "        if del_name in sub_list:\n",
    "            list_1.remove(sub_list)\n",
    "    return list_1\n",
    "\n",
    "deleting(temp, 'none')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursive_len(item):\n",
    "    if type(item) == list:\n",
    "        return sum(recursive_len(subitem) for subitem in item)\n",
    "    else:\n",
    "        return 1\n",
    "recursive_len(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Run Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import corpora\n",
    "dictionary = corpora.Dictionary(temp)\n",
    "dictionary.filter_extremes(no_below=10, no_above=0.5, keep_n=8000)\n",
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in temp]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Full Run LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Creating the object for LDA model using gensim library\n",
    "Lda = gensim.models.ldamodel.LdaModel\n",
    "\n",
    "# Running and Trainign LDA model on the document term matrix.\n",
    "ldamodel = Lda(doc_term_matrix, num_topics=10, per_word_topics=True, id2word = dictionary, passes=100, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ldamodel.print_topics(num_topics=10, num_words=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Creating the object for LDA model using gensim library\n",
    "Lda = gensim.models.ldamodel.LdaModel\n",
    "\n",
    "# Running and Trainign LDA model on the document term matrix.\n",
    "ldamodel2 = Lda(doc_term_matrix, num_topics=10, per_word_topics=True, id2word = dictionary, passes=100, random_state=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ldamodel2.print_topics(num_topics=10, num_words=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Creating the object for LDA model using gensim library\n",
    "Lda = gensim.models.ldamodel.LdaModel\n",
    "\n",
    "# Running and Trainign LDA model on the document term matrix.\n",
    "ldamodel3 = Lda(doc_term_matrix, num_topics=10, per_word_topics=True, id2word = dictionary, passes=100, random_state=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ldamodel3.print_topics(num_topics=10, num_words=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Full Run Multi-Core LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lda_modelmulti = gensim.models.LdaMulticore(doc_term_matrix, num_topics=10, id2word=dictionary, passes=2, workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lda_modelmulti.print_topics(num_topics=10, num_words=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lda_modelmulti2 = gensim.models.LdaMulticore(doc_term_matrix, num_topics=10, id2word=dictionary, passes=2, workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lda_modelmulti2.print_topics(num_topics=10, num_words=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "words_to_ignore = ['lamb', 'pork', 'beef', 'chicken', 'duck', 'oyster', 'clam', 'clams', 'oysters', 'cheese', 'eggs', 'bacon', 'pizza']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lda_modelmulti3 = gensim.models.LdaMulticore(doc_term_matrix, num_topics=10, alpha='asymmetric', id2word=dictionary, passes=30, workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lda_modelmulti3.print_topics(num_topics=10, num_words=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Service Only Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('reviews_manhattan.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(value=str('none'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Unnamed: 0', 'Restaurant_Id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['Review'] = df['Review'].apply(remove_punctuations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Review'] = df['Review'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Review'] = df['Review'].str.replace('\\d+', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['Review'] = df['Review'].apply(lambda x: ' '.join([item for item in x.split() if item not in stop]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[df['Review'].str.contains('service')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "df1['Review'] = df1['Review'].apply(lambda x: ' '.join([lemmatizer.lemmatize(word, pos = 'v') for word in x.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "df1['token_Review']= df1['Review'].apply(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.drop(columns=['Review'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenslist = df1.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "for row in tokenslist:\n",
    "    if type(row) == list:\n",
    "        temp.extend(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting rid of nones\n",
    "def deleting(list_1,del_name):\n",
    "    for sub_list in tqdm(list_1):\n",
    "        if del_name in sub_list:\n",
    "            list_1.remove(sub_list)\n",
    "    return list_1\n",
    "\n",
    "deleting(temp, 'none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final removal of stop words post lemmetization\n",
    "temps=[]\n",
    "for review in temp:\n",
    "    wr=[]\n",
    "    for word in review:\n",
    "        if word not in stop:\n",
    "            wr.append(word)\n",
    "    temps.append(wr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#37400\n",
    "len(temps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Prepping for TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "temp = [' '.join(x) for x in temp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tfidf_review = tfidf.fit_transform(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tfidf_review[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pf = pd.DataFrame(tfidf_review.toarray(), columns=tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pf.mehhhhh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import corpora\n",
    "dictionary = corpora.Dictionary(temps)\n",
    "dictionary.filter_extremes(no_below=10, no_above=0.5, keep_n=8000)\n",
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in temps]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the object for LDA model using gensim library\n",
    "Lda = gensim.models.ldamodel.LdaModel\n",
    "\n",
    "# Running and Trainign LDA model on the document term matrix.\n",
    "ldamodel = Lda(doc_term_matrix, num_topics=12, per_word_topics=True, id2word = dictionary, passes=50, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ldamodel.print_topics(num_topics=12, num_words=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'least', 'lack', 'reason', 'either', 'miss', 'hours', 'rat', 'guess', 'instead', 'understand', 'mind', 'outstanding', 'platter', 'rude', 'greet', 'guy', 'girl', 'woman', 'man', 'cold', 'soft', 'white', 'fixe', 'pre', 'prix', 'refresh', 'le', 'range', 'terrific', 'craft', 'hill', 'non', 'pot', 'win', 'live', 'weekend', 'surprise', 'shack', 'po', 'raw', 'dozen'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath\n",
    "# Save model to disk.\n",
    "\n",
    "ldamodel.save('ldabest.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the object for LDA model using gensim library\n",
    "Lda = gensim.models.ldamodel.LdaModel\n",
    "\n",
    "# Running and Trainign LDA model on the document term matrix.\n",
    "ldamodel2 = Lda(doc_term_matrix, num_topics=12, per_word_topics=True, id2word = dictionary, passes=50, random_state=55)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldamodel2.print_topics(num_topics=12, num_words=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['dry', 'half', 'use', 'anything', 'mean', 'honestly', 'almost', 'summer', 'close', 'rich', 'salty', 'red', 'couple', 'plat', 'show', 'occasion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath\n",
    "# Save model to disk.\n",
    "\n",
    "ldamodel.save('ldabest2.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(ldamodel, doc_term_matrix, dictionary)\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(80,60))\n",
    "for t in range(ldamodel.num_topics):\n",
    "    plt.figure()\n",
    "    plt.imshow(WordCloud(width=1000, height=600, scale=5).fit_words(dict(ldamodel.show_topic(t, 200))))\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"Topic #\" + str(t))\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "222px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
